{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from pandas.tseries.offsets import YearBegin\n",
    "from pandas.tseries.offsets import MonthBegin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metropolis_hastrings(log_posteior_function, initial, a_vector_idx, c_vector_idx, \n",
    "                         p_vector_idx, s_vector_idx, a_sample_idx, c_sample_idx, \n",
    "                         p_sample_idx, a_max, c_max, p_max, N, D, \n",
    "                         scale=[0.013, 0.013, 0.013, 0.013, 1, 1], \n",
    "                         shape=100, rate=2, iteration=10, seed=99999):\n",
    "    \n",
    "    current = initial    \n",
    "    samples = np.zeros((iteration, initial.shape[0]))\n",
    "    scale_vector = np.zeros(current.shape[0])\n",
    "    max_ = 0\n",
    "    acceptance_ = 0\n",
    "    \n",
    "    #set scale_vector for a, c, p, s, kappa and mu\n",
    "    for i, max_index in enumerate((a_max, c_max, p_max)):       \n",
    "        scale_vector[max_:(max_+max_index)] = scale[i]*np.ones(max_index)\n",
    "        max_ += max_index\n",
    "    scale_vector[-16:-4] = scale[3]*np.ones(12)\n",
    "    scale_vector[-4:-1] = scale[4]*np.ones(3)\n",
    "    scale_vector[-1] = scale[5]\n",
    "    \n",
    "    np.random.seed(seed=seed)\n",
    "    for i in range(iteration):        \n",
    "        candidate = np.zeros(current.shape[0])      \n",
    "        #random draw a, c, p, s\n",
    "        candidate = current + scale_vector*np.random.normal(size=current.shape[0])       \n",
    "        \n",
    "        logPosterior_current = log_posteior_function(params=current, a_vector_idx=a_vector_idx, \n",
    "                                      c_vector_idx=c_vector_idx, p_vector_idx=p_vector_idx, \n",
    "                                      s_vector_idx=s_vector_idx, a_sample_idx=a_sample_idx, \n",
    "                                      c_sample_idx=c_sample_idx, p_sample_idx=p_sample_idx, \n",
    "                                      N=N, D=D)\n",
    "        logPosterior_candidate = log_posteior_function(params=candidate, a_vector_idx=a_vector_idx, \n",
    "                                      c_vector_idx=c_vector_idx, p_vector_idx=p_vector_idx, \n",
    "                                      s_vector_idx=s_vector_idx, a_sample_idx=a_sample_idx, \n",
    "                                      c_sample_idx=c_sample_idx, p_sample_idx=p_sample_idx, \n",
    "                                      N=N, D=D)\n",
    "        \n",
    "        if logPosterior_candidate - logPosterior_current > np.log(np.random.rand()):\n",
    "            current = candidate\n",
    "            acceptance_ += 1\n",
    "        \n",
    "        samples[i, :] = current\n",
    "        acceptance_rate = acceptance_/iteration\n",
    "    \n",
    "    return (samples, acceptance_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logPosterior(params, a_vector_idx, c_vector_idx, p_vector_idx, s_vector_idx,\n",
    "                 a_sample_idx, c_sample_idx, p_sample_idx, N, D, shape=100, rate=2): \n",
    "       \n",
    "    if np.absolute(params[-1]) > 100:\n",
    "        eta = np.NINF\n",
    "    else:\n",
    "        eta = params[a_vector_idx] + params[c_vector_idx] + params[p_vector_idx] + \\\n",
    "                params[s_vector_idx] + params[-1]\n",
    "\n",
    "    log_posterior = logKappa(params[-4:-1], shape, rate) + logPrior(params[a_sample_idx],\n",
    "                    params[c_sample_idx], params[p_sample_idx],\n",
    "                    params[-4:-1]) + logLikelihood(N, D, eta)\n",
    "    \n",
    "    return log_posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logKappa(kappa, shape=100, rate=2):\n",
    "    if np.any(kappa <= 0):\n",
    "        return np.NINF\n",
    "    else:\n",
    "        return np.sum((shape-1)*np.log(kappa) - rate*kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logPrior(a_sample, c_sample, p_sample, kappa):\n",
    "    \n",
    "    log_prior = 0       \n",
    "    for i, sample in enumerate((a_sample, c_sample, p_sample)):\n",
    "        if np.all(sample < 50):\n",
    "            log_prior += np.log(kappa[i])*(sample.shape[0]-1)/2 - \\\n",
    "                         kappa[i]*np.sum(np.power((sample[1:]-sample[:-1]), 2))/2\n",
    "        else:\n",
    "            log_prior += np.NINF\n",
    "            \n",
    "    return log_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logLikelihood(N, D, eta):\n",
    "\n",
    "    #calculate log_eta with method to prevent overflow    \n",
    "    log_p = np.zeros(eta.shape[0])\n",
    "    log_p[eta>=0] = -1*np.log(1+np.exp(-1*eta[eta>=0]))\n",
    "    log_p[eta<0] = eta[eta<0] - np.log(1+np.exp(eta[eta<0]))\n",
    "    \n",
    "    log_q = np.zeros(eta.shape[0])\n",
    "    log_q[eta>=0] = -1*eta[eta>=0] - np.log(1+np.exp(-1*eta[eta>=0]))\n",
    "    log_q[eta<0] = -1*np.log(1+np.exp(eta[eta<0]))\n",
    "    \n",
    "    log_likelihood = np.sum(N*log_p + (D-N)*log_q)\n",
    "    \n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialization(data, age_col, cohort_col, period_col, seasonality=None, shape=100, rate=2,):\n",
    "    \n",
    "    data_ = data.dropna()\n",
    "    component_idx = {} #dictionary for the index of a, c, p and s\n",
    "    \n",
    "    component_idx['age'] = data_[age_col].astype(int).values\n",
    "    component_idx['cohort'] = (data_[cohort_col] - data_[cohort_col].min()).astype(int).values\n",
    "    component_idx['period'] = (data_[period_col] - data_[period_col].min()).astype(int).values\n",
    "    \n",
    "    if seasonality is not None:\n",
    "        component_idx['seasonality'] = (data_[period_col].dt.strftime('%m').astype(int)).values\n",
    "    else:\n",
    "        component_idx['seasonality'] = np.zeros(data_.shape[0])\n",
    "    \n",
    "    sample_vector_length = component_idx['age'].max() + component_idx['cohort'].max() + \\\n",
    "                            component_idx['period'].max() + 16 # 12 for seasonality, 3 or kappa and 1 for mu\n",
    "    \n",
    "    #sample vector contains a, c, p, s, kappa and mu. a, c, p contains values that may not have a correspoding\n",
    "    #one in the index from the data, as 1:max is all created\n",
    "    init = np.zeros(sample_vector_length)  #initialize everything to 0\n",
    "    init[-4:-1] = np.random.gamma(shape, 1/rate, 3) #initialize kappa with random draw from gamma distribution\n",
    "    \n",
    "    return (init, component_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>mortality</th>\n",
       "      <th>population</th>\n",
       "      <th>period</th>\n",
       "      <th>cohort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1935-01-01</td>\n",
       "      <td>50</td>\n",
       "      <td>177</td>\n",
       "      <td>301000</td>\n",
       "      <td>1935-01</td>\n",
       "      <td>1885-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1935-01-01</td>\n",
       "      <td>55</td>\n",
       "      <td>262</td>\n",
       "      <td>212000</td>\n",
       "      <td>1935-01</td>\n",
       "      <td>1880-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1935-01-01</td>\n",
       "      <td>60</td>\n",
       "      <td>360</td>\n",
       "      <td>159000</td>\n",
       "      <td>1935-01</td>\n",
       "      <td>1875-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1935-01-01</td>\n",
       "      <td>65</td>\n",
       "      <td>409</td>\n",
       "      <td>132000</td>\n",
       "      <td>1935-01</td>\n",
       "      <td>1870-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1935-01-01</td>\n",
       "      <td>70</td>\n",
       "      <td>328</td>\n",
       "      <td>76000</td>\n",
       "      <td>1935-01</td>\n",
       "      <td>1865-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        time age  mortality  population  period  cohort\n",
       "0 1935-01-01  50        177      301000 1935-01 1885-01\n",
       "1 1935-01-01  55        262      212000 1935-01 1880-01\n",
       "2 1935-01-01  60        360      159000 1935-01 1875-01\n",
       "3 1935-01-01  65        409      132000 1935-01 1870-01\n",
       "4 1935-01-01  70        328       76000 1935-01 1865-01"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\LI09432\\\\Documents\\\\BayesianAPC\\\\data\\\\Holford1983Biometrics.csv', parse_dates=[1], \n",
    "                   skiprows=5)\n",
    "data['time'] = pd.to_datetime(data['time'], format=\"%Y-%m\")\n",
    "data['period'] = data['time'].dt.to_period('M')\n",
    "data['cohort'] = data['time'] - pd.to_timedelta(data['age'].astype(int), unit='Y')\n",
    "data['cohort'] = data['cohort'] + MonthBegin()\n",
    "data['cohort'] = data['cohort'].dt.to_period('M')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 19.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#initialize sample vector and index vector\n",
    "init, idx = initialization(data, 'age', 'cohort', 'period')\n",
    "\n",
    "#sample_idx contains the idx of sorted unique numerical a, c, p\n",
    "#vector_idx contains the idx of numerical a, c, p and s in the train sample\n",
    "#idx_max contains the max of a, c, and p\n",
    "#notice that sample_idx is from 0 to max for each component but vector_idx doesn't\n",
    "#necessarily contain all the sample_idx (e.g. some cohorts are missing)\n",
    "sample_idx = {}\n",
    "vector_idx = {}\n",
    "idx_max = np.zeros(3)\n",
    "\n",
    "for i, component in enumerate(['age', 'cohort', 'period', 'seasonality']):   \n",
    "     if i < 3:\n",
    "        sample_idx[component] = (np.unique(idx[component]) + np.sum(idx_max)).astype(int)\n",
    "        vector_idx[component] = (idx[component] + np.sum(idx_max)).astype(int)\n",
    "        idx_max[i] = idx[component].max()\n",
    "     else:\n",
    "        vector_idx[component] = (idx[component] + np.sum(idx_max) - 1).astype(int)\n",
    "\n",
    "idx_max = idx_max.astype(int)\n",
    "N = data['mortality'].values\n",
    "D = data['population'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result, acceptance_rate = metropolis_hastrings(log_posteior_function=logPosterior, initial=init, a_vector_idx=vector_idx['age'],\n",
    "                      c_vector_idx=vector_idx['cohort'], p_vector_idx=vector_idx['period'], \n",
    "                    s_vector_idx=vector_idx['seasonality'], a_sample_idx=sample_idx['age'], \n",
    "                    c_sample_idx=sample_idx['cohort'], p_sample_idx=sample_idx['period'], a_max=idx_max[0],\n",
    "                      c_max=idx_max[1], p_max=idx_max[2], scale=[0.005, 0.005, 0.005, 0.005, 0.01, 0.01], \n",
    "                                               N=N, D=D, iteration=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
